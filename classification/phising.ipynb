{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rt  # url library open urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=rt.request('get','https://archive.ics.uci.edu/ml/machine-learning-databases/00327/.old.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package scipy.io.arff in scipy.io:\n",
      "\n",
      "NAME\n",
      "    scipy.io.arff\n",
      "\n",
      "DESCRIPTION\n",
      "    Module to read ARFF files\n",
      "    =========================\n",
      "    ARFF is the standard data format for WEKA.\n",
      "    It is a text file format which support numerical, string and data values.\n",
      "    The format can also represent missing data and sparse data.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The ARFF support in ``scipy.io`` provides file reading functionality only.\n",
      "    For more extensive ARFF functionality, see `liac-arff\n",
      "    <https://github.com/renatopp/liac-arff>`_.\n",
      "    \n",
      "    See the `WEKA website <http://weka.wikispaces.com/ARFF>`_\n",
      "    for more details about the ARFF format and available datasets.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    arffread\n",
      "    setup\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.OSError(builtins.Exception)\n",
      "        scipy.io.arff.arffread.ArffError\n",
      "            scipy.io.arff.arffread.ParseArffError\n",
      "    builtins.object\n",
      "        scipy.io.arff.arffread.MetaData\n",
      "    \n",
      "    class ArffError(builtins.OSError)\n",
      "     |  Base class for I/O related errors.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ArffError\n",
      "     |      builtins.OSError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.OSError:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.OSError:\n",
      "     |  \n",
      "     |  characters_written\n",
      "     |  \n",
      "     |  errno\n",
      "     |      POSIX exception code\n",
      "     |  \n",
      "     |  filename\n",
      "     |      exception filename\n",
      "     |  \n",
      "     |  filename2\n",
      "     |      second exception filename\n",
      "     |  \n",
      "     |  strerror\n",
      "     |      exception strerror\n",
      "     |  \n",
      "     |  winerror\n",
      "     |      Win32 exception code\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class MetaData(builtins.object)\n",
      "     |  Small container to keep useful information on a ARFF dataset.\n",
      "     |  \n",
      "     |  Knows about attributes names and types.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  ::\n",
      "     |  \n",
      "     |      data, meta = loadarff('iris.arff')\n",
      "     |      # This will print the attributes names of the iris.arff dataset\n",
      "     |      for i in meta:\n",
      "     |          print(i)\n",
      "     |      # This works too\n",
      "     |      meta.names()\n",
      "     |      # Getting attribute type\n",
      "     |      types = meta.types()\n",
      "     |  \n",
      "     |  Methods\n",
      "     |  -------\n",
      "     |  names\n",
      "     |  types\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Also maintains the list of attributes in order, i.e. doing for i in\n",
      "     |  meta, where meta is an instance of MetaData, will return the\n",
      "     |  different attribute names in the order they were defined.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __init__(self, rel, attr)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  names(self)\n",
      "     |      Return the list of attribute names.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      attrnames : list of str\n",
      "     |          The attribute names.\n",
      "     |  \n",
      "     |  types(self)\n",
      "     |      Return the list of attribute types.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      attr_types : list of str\n",
      "     |          The attribute types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ParseArffError(ArffError)\n",
      "     |  Base class for I/O related errors.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ParseArffError\n",
      "     |      ArffError\n",
      "     |      builtins.OSError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors inherited from ArffError:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.OSError:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.OSError:\n",
      "     |  \n",
      "     |  characters_written\n",
      "     |  \n",
      "     |  errno\n",
      "     |      POSIX exception code\n",
      "     |  \n",
      "     |  filename\n",
      "     |      exception filename\n",
      "     |  \n",
      "     |  filename2\n",
      "     |      second exception filename\n",
      "     |  \n",
      "     |  strerror\n",
      "     |      exception strerror\n",
      "     |  \n",
      "     |  winerror\n",
      "     |      Win32 exception code\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "FUNCTIONS\n",
      "    loadarff(f)\n",
      "        Read an arff file.\n",
      "        \n",
      "        The data is returned as a record array, which can be accessed much like\n",
      "        a dictionary of numpy arrays.  For example, if one of the attributes is\n",
      "        called 'pressure', then its first 10 data points can be accessed from the\n",
      "        ``data`` record array like so: ``data['pressure'][0:10]``\n",
      "        \n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        f : file-like or str\n",
      "           File-like object to read from, or filename to open.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : record array\n",
      "           The data of the arff file, accessible by attribute names.\n",
      "        meta : `MetaData`\n",
      "           Contains information about the arff file such as name and\n",
      "           type of attributes, the relation (name of the dataset), etc...\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        ParseArffError\n",
      "            This is raised if the given file is not ARFF-formatted.\n",
      "        NotImplementedError\n",
      "            The ARFF file has an attribute which is not supported yet.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        This function should be able to read most arff files. Not\n",
      "        implemented functionality include:\n",
      "        \n",
      "        * date type attributes\n",
      "        * string type attributes\n",
      "        \n",
      "        It can read files with numeric and nominal attributes.  It cannot read\n",
      "        files with sparse data ({} in the file).  However, this function can\n",
      "        read files with missing data (? in the file), representing the data\n",
      "        points as NaNs.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.io import arff\n",
      "        >>> from io import StringIO\n",
      "        >>> content = \"\"\"\n",
      "        ... @relation foo\n",
      "        ... @attribute width  numeric\n",
      "        ... @attribute height numeric\n",
      "        ... @attribute color  {red,green,blue,yellow,black}\n",
      "        ... @data\n",
      "        ... 5.0,3.25,blue\n",
      "        ... 4.5,3.75,green\n",
      "        ... 3.0,4.00,red\n",
      "        ... \"\"\"\n",
      "        >>> f = StringIO(content)\n",
      "        >>> data, meta = arff.loadarff(f)\n",
      "        >>> data\n",
      "        array([(5.0, 3.25, 'blue'), (4.5, 3.75, 'green'), (3.0, 4.0, 'red')],\n",
      "              dtype=[('width', '<f8'), ('height', '<f8'), ('color', '|S6')])\n",
      "        >>> meta\n",
      "        Dataset: foo\n",
      "            width's type is numeric\n",
      "            height's type is numeric\n",
      "            color's type is nominal, range is ('red', 'green', 'blue', 'yellow', 'black')\n",
      "\n",
      "DATA\n",
      "    __all__ = ['MetaData', 'loadarff', 'ArffError', 'ParseArffError']\n",
      "\n",
      "FILE\n",
      "    c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\io\\arff\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=StringIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-094b1cda6478>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadarff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\io\\arff\\arffread.py\u001b[0m in \u001b[0;36mloadarff\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[0mofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_loadarff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mofile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mofile\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# only close what we opened\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\io\\arff\\arffread.py\u001b[0m in \u001b[0;36m_loadarff\u001b[1;34m(ofile)\u001b[0m\n\u001b[0;32m    812\u001b[0m     \u001b[1;31m# Parse the header file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mrel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mofile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Error while parsing header, error was: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\io\\arff\\arffread.py\u001b[0m in \u001b[0;36mread_header\u001b[1;34m(ofile)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mofile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[1;34m\"\"\"Read the header of the iterable ofile.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mofile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[1;31m# Pass first comments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dt=arff.loadarff(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-66cb24d42d5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dt' is not defined"
     ]
    }
   ],
   "source": [
    "col=dt.columns\n",
    "for i in col:\n",
    "    dt[i]=dt[i].astype(dtype='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2456, 30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dt.drop('Result',axis=1)\n",
    "y=dt['Result']\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_ts,y_tr,y_ts=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93495934959349591"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "algo1=KNeighborsClassifier()\n",
    "algo1.fit(x_tr,y_tr)\n",
    "algo1.score(x_ts,y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89430894308943087"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "algo2=GaussianNB()\n",
    "algo2.fit(x_tr,y_tr)\n",
    "algo2.score(x_ts,y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92682926829268297"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "algo3=LogisticRegression()\n",
    "algo3.fit(x_tr,y_tr)\n",
    "algo3.score(x_ts,y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93699186991869921"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "algo4=SVC()\n",
    "algo4.fit(x_tr,y_tr)\n",
    "algo4.score(x_ts,y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95934959349593496"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algo5=DecisionTreeClassifier()\n",
    "algo5.fit(x_tr,y_tr)\n",
    "algo5.score(x_ts,y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95731707317073167"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algo6=RandomForestClassifier()\n",
    "algo6.fit(x_tr,y_tr)\n",
    "algo6.score(x_ts,y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.93495934959349591, 0.89430894308943087, 0.92682926829268297)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo1.score(x_ts,y_ts),algo2.score(x_ts,y_ts),algo3.score(x_ts,y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.93699186991869921, 0.95934959349593496, 0.95731707317073167)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo4.score(x_ts,y_ts),algo5.score(x_ts,y_ts),algo6.score(x_ts,y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition.pca import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=PCA(2)\n",
    "p.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr1=p.transform(x_tr)\n",
    "x_ts1=p.transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amit\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\amit\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo1.fit(x_tr1,y_tr)\n",
    "algo2.fit(x_tr1,y_tr)\n",
    "algo3.fit(x_tr1,y_tr)\n",
    "algo4.fit(x_tr1,y_tr)\n",
    "algo5.fit(x_tr1,y_tr)\n",
    "algo6.fit(x_tr1,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89634146341463417, 0.87804878048780488, 0.88211382113821135)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo1.score(x_ts1,y_ts),algo2.score(x_ts1,y_ts),algo3.score(x_ts1,y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88211382113821135, 0.9065040650406504, 0.90447154471544711)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo4.score(x_ts1,y_ts),algo5.score(x_ts1,y_ts),algo6.score(x_ts1,y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1964, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
